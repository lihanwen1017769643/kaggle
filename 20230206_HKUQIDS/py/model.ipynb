{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HKU QIDS 2023 Quantitative Investment Competition: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from qids_package.qids import *\n",
    "import warnings\n",
    "from submit import submit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 257248\n",
    "stock_num = 54\n",
    "day_num_total = 1000\n",
    "day_num = 1000 - 2\n",
    "test_day_num = 700\n",
    "timeslot_num = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(train, valid, test=None):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    valid = scaler.transform(valid)\n",
    "    if test is not None:\n",
    "        test = scaler.transform(test)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corr(df1, df2):\n",
    "    return np.corrcoef(df1, df2)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, train, valid, test, train_y, valid_y, return_pred=True, version=2, return_auc=False, plot_auc=False):\n",
    "    model.fit(train, train_y)\n",
    "    if version == 2:\n",
    "        model_train_y = model.predict(train)\n",
    "        model_valid_y = model.predict(valid)\n",
    "        pred = model.predict(test)\n",
    "        acr_train = model.score(train, train_y)\n",
    "        acr_valid = model.score(valid, valid_y)\n",
    "        print(calc_corr(train_y, model_train_y))\n",
    "        print(calc_corr(valid_y, model_valid_y))\n",
    "        if return_pred:\n",
    "            return pred\n",
    "    #     cm = confusion_matrix(train_y, model_train_y)\n",
    "    #     tn, fp, fn, tp = cm.ravel()\n",
    "    #     print(f\"Train AUROC: {roc_auc_score(train_y, model_train_y):.4f}; FP: {fp:>4d}; FN: {fn:>4d}\")\n",
    "    #     cm = confusion_matrix(valid_y, model_valid_y)\n",
    "    #     tn, fp, fn, tp = cm.ravel()\n",
    "    #     print(f\"Valid AUROC: {roc_auc_score(valid_y, model_valid_y):.4f}; FP: {fp:>4d}; FN: {fn:>4d}\")\n",
    "    #     print()\n",
    "    # elif version == 3:\n",
    "    #     pred_train = model.predict(train)\n",
    "    #     pred_valid = model.predict(valid)\n",
    "    #     pred = model.predict(test)\n",
    "    #     print(f\"Train RMSE: {mse(train_y, pred_train, squared=False):.4f}\")\n",
    "    #     print(f\"Valid RMSE: {mse(valid_y, pred_valid, squared=False):.4f}\")\n",
    "    # else:\n",
    "    #     model_train_y = model.predict_proba(train)[:,1]\n",
    "    #     model_valid_y = model.predict_proba(valid)[:,1]\n",
    "    #     pred = model.predict_proba(test)[:,1]\n",
    "    #     acr_train = model.score(train, train_y)\n",
    "    #     acr_valid = model.score(valid, valid_y)\n",
    "    #     print(f\"Train Accuracy: {acr_train:.4f}; Validation Accuracy: {acr_valid:.4f}\")\n",
    "    #     auc_train = roc_auc_score(train_y, model_train_y)\n",
    "    #     auc_valid = roc_auc_score(valid_y, model_valid_y)\n",
    "    #     print(f\"Train AUROC: {auc_train:.4f}\")\n",
    "    #     print(f\"Valid AUROC: {auc_valid:.4f}\")\n",
    "    #     print()\n",
    "    # if plot_auc:\n",
    "    #     try:\n",
    "    #         fpr1, tpr1, thresholds1 = roc_curve(train_y, model_train_y)\n",
    "    #         fpr2, tpr2, thresholds2 = roc_curve(valid_y, model_valid_y)\n",
    "    #         plt.plot([0,1], 'k--')\n",
    "    #         plt.plot(fpr1, tpr1, label= \"Train\")\n",
    "    #         plt.plot(fpr2, tpr2, label= \"Valid\")\n",
    "    #         plt.legend()\n",
    "    #         plt.xlabel(\"FPR\")\n",
    "    #         plt.ylabel(\"TPR\")\n",
    "    #         plt.title('AUROC Curve')\n",
    "    #         plt.show()\n",
    "    #     except:\n",
    "    #         pass\n",
    "    # if return_pred and return_auc and version == 1:\n",
    "    #     return pred, auc_train, auc_valid\n",
    "    # elif return_pred:\n",
    "    #     return pred\n",
    "    # else:\n",
    "    #     return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = \"../data/\"\n",
    "\n",
    "train_path = write_path + \"train.csv\"\n",
    "valid_path = write_path + \"valid.csv\"\n",
    "test_path = write_path + \"test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "valid = pd.read_csv(valid_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[\"return\"]\n",
    "train = train.drop(columns=[\"return\", \"date_time\"])\n",
    "\n",
    "valid_y = valid[\"return\"]\n",
    "valid = valid.drop(columns=[\"return\", \"date_time\"])\n",
    "\n",
    "test = test.drop(columns=[\"date_time\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid, test = std(train.iloc[:, 3:-1], valid.iloc[:, 3:-1], test.iloc[:, 3:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08990825442268606\n",
      "0.08413533119889033\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "pred = evaluate(model, train, valid, test, train_y, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00098012, -0.00070065, -0.00069922, ..., -0.00972251,\n",
       "       -0.00787746, -0.00710269])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "800b2c1448e2ea079d66e8039536a26ab9dab7a446f882031feb022006dbbbf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
