{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import lightgbm as lgb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import tqdm\n",
    "\n",
    "n_fold = 10\n",
    "group_gap = 31\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"../../data/\"\n",
    "TRAIN_MARKET_PATH = f'{ROOT_PATH}first_round_train_market_data.csv'\n",
    "# TRAIN_MARKET_PATH = f'{ROOT_PATH}train.csv'\n",
    "TRAIN_FUNADMENTAL_PATH = f'{ROOT_PATH}first_round_train_fundamental_data.csv'\n",
    "TRAIN_RETURN_PATH = f'{ROOT_PATH}first_round_train_return_data.csv'\n",
    "\n",
    "TEST_ROOT_PATH = \"../qids_package/\"\n",
    "TEST_MARKET_PATH = f'{TEST_ROOT_PATH}first_round_test_market_data.csv'\n",
    "# TEST_MARKET_PATH = f'{ROOT_PATH}test.csv'\n",
    "TEST_FUNADMENTAL_PATH = f'{TEST_ROOT_PATH}first_round_test_fundamental_data.csv'\n",
    "\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 350)\n",
    "\n",
    "#read data\n",
    "df_train_market = pd.read_csv(TRAIN_MARKET_PATH)\n",
    "df_train_return = pd.read_csv(TRAIN_RETURN_PATH)\n",
    "df_train_fundamental = pd.read_csv(TRAIN_FUNADMENTAL_PATH)\n",
    "\n",
    "df_test_market = pd.read_csv(TEST_MARKET_PATH)\n",
    "df_test_fundamental = pd.read_csv(TEST_FUNADMENTAL_PATH)\n",
    "\n",
    "#merge train dataset and test dataset\n",
    "def split_time(x):\n",
    "    df1 = x['date_time'].str.split('d', expand=True)\n",
    "    df1.columns=['code','s']\n",
    "    code = df1['code']\n",
    "    df1 = df1['s'].str.split('p', expand=True)\n",
    "    df1.columns=['day','time_step']\n",
    "    df2 = x['date_time'].str.rsplit('p', expand=True)\n",
    "    df2.columns=['day_s','s']\n",
    "    df1['day_s'] = df2['day_s']\n",
    "    df1['code'] = code\n",
    "    x = pd.concat([x,df1],axis=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "df_train_market = split_time(df_train_market)\n",
    "df = pd.merge(df_train_fundamental,df_train_market, left_on='date_time',right_on='day_s')  \n",
    "df = pd.merge(df,df_train_return, left_on='day_s',right_on='date_time')  \n",
    "\n",
    "df_test_market = split_time(df_test_market)\n",
    "test = pd.merge(df_test_fundamental,df_test_market, left_on='date_time',right_on='day_s')  \n",
    "\n",
    "#drop duplicates\n",
    "df = df.drop_duplicates(subset='day_s', keep='last').reset_index(drop=True)\n",
    "test = test.drop_duplicates(subset='day_s', keep='last').reset_index(drop=True)\n",
    "\n",
    "def growth(data, features, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create growth rate column based on selected features\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for feature in features:\n",
    "        data[f'{feature}_growth'] = grouped[feature].pct_change()\n",
    "        \n",
    "    return data\n",
    "\n",
    "def lag_feature_with_group(data, features, n, group):\n",
    "\n",
    "    \"\"\"\n",
    "    create a lagged column in data from feature with n lagging periods\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for feature in features:\n",
    "            data[f'{feature}_{i}'] = grouped[feature].shift(i)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def sma(data, features, n, group):\n",
    "    \n",
    "    \"\"\"\n",
    "    create sma(n) column in data from feature\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped = data.groupby(group)\n",
    "    \n",
    "    for i in n:\n",
    "        for feature in features:\n",
    "            data[f'{feature}_sma{i}'] = grouped.rolling(i)[feature].mean().reset_index(drop=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "features = ['pe_ttm', 'pe', 'pb', 'ps', 'pcf']\n",
    "sma_periods = [10,25,50]\n",
    "df_lag = lag_feature_with_group(df, features, 2, 'code')\n",
    "df_sma = sma(df_lag, features, sma_periods, 'code')\n",
    "df_growth = growth(df_sma, features, 'code')\n",
    "# fig, ax = plt.subplots(figsize=(7,15))\n",
    "# sns.heatmap(df_lag.corr(numeric_only=True)[['return']].sort_values(by='return', ascending=False),annot=True);\n",
    "\n",
    "test = lag_feature_with_group(test, features, 2, 'code')\n",
    "test = sma(test, features, sma_periods, 'code')\n",
    "test = growth(test, features, 'code')\n",
    "\n",
    "# df = df.dropna()\n",
    "# test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 257248\n",
    "stock_num = 54\n",
    "train_day_num_total = 1000\n",
    "train_day_num = 1000 - 2\n",
    "test_day_num = 700\n",
    "timeslot_num = 50\n",
    "\n",
    "calc_log = lambda df: np.log(np.where(df > 1e-8, df, 1e-8))\n",
    "calc_mean = lambda df: df.mean(axis=0)\n",
    "calc_max = lambda df: df.max(axis=0)\n",
    "calc_min = lambda df: df.min(axis=0)\n",
    "calc_std = lambda df: df.std()\n",
    "calc_var = lambda df: df.var()\n",
    "calc_add = lambda df1, df2: df1 + df2\n",
    "calc_diff = lambda df1, df2: df1 - df2\n",
    "calc_prod = lambda df1, df2: df1 * df2\n",
    "calc_div = lambda df1, df2: df1 / df2\n",
    "\n",
    "def preprocess(fun, mar, ret=None):\n",
    "    fun[\"stock_id\"] = fun[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "    fun[\"day\"] = fun[\"date_time\"].apply(lambda x: x.split(\"d\")[1][:]).astype(\"int\")\n",
    "    # fun[\"log_pb\"] = calc_log(fun[\"pb\"])\n",
    "    # fun[\"log_ps\"] = calc_log(fun[\"ps\"])\n",
    "    fun = fun.sort_values(by=[\"stock_id\", \"day\"])\n",
    "    na_fun = fun.loc[fun[\"day\"].isin([999, 1000])]\n",
    "    fun = fun.drop(na_fun.index, axis=0).reset_index(drop=True)\n",
    "    na_fun = na_fun.reset_index(drop=True)\n",
    "\n",
    "    mar[\"stock_id\"] = mar[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "    mar[\"day\"] = mar[\"date_time\"].apply(lambda x: x.split(\"d\")[1].split(\"p\")[0]).astype(\"int\")\n",
    "    mar[\"time\"] = mar[\"date_time\"].apply(lambda x: x.split(\"p\")[1]).astype(\"int\")\n",
    "    mar = mar.sort_values(by=[\"stock_id\", \"day\", \"time\"]).reset_index(drop=True)\n",
    "    na_mar = mar.loc[mar[\"day\"].isin([999, 1000])]\n",
    "    mar = mar.drop(na_mar.index, axis=0).reset_index(drop=True)\n",
    "    na_mar = na_mar.reset_index(drop=True)\n",
    "\n",
    "    combined = copy.deepcopy(fun)\n",
    "    if ret is not None:\n",
    "        ret[\"stock_id\"] = ret[\"date_time\"].apply(lambda x: x.split(\"d\")[0][1:]).astype(\"int\")\n",
    "        ret[\"day\"] = ret[\"date_time\"].apply(lambda x: x.split(\"d\")[1][:]).astype(\"int\")\n",
    "        # ret[\"log_pb\"] = calc_log(ret[\"pb\"])\n",
    "        # ret[\"log_ps\"] = calc_log(ret[\"ps\"])\n",
    "        ret = ret.sort_values(by=[\"stock_id\", \"day\"]).reset_index(drop=True)\n",
    "        combined[\"return\"] = ret[\"return\"]\n",
    "        day_num = train_day_num\n",
    "    else:\n",
    "        day_num = test_day_num\n",
    "\n",
    "    mar_summary = []\n",
    "    start = 0\n",
    "    for stock in range(stock_num):\n",
    "        end = start + day_num * timeslot_num\n",
    "        stock_info = mar.iloc[start:end, :]\n",
    "        day_start = 0\n",
    "        for day in range(day_num):\n",
    "            day_end = day_start + timeslot_num\n",
    "            stock_info_per_day = stock_info.iloc[day_start:day_end, :]\n",
    "            mar_summary.append([\n",
    "                calc_mean(stock_info_per_day[\"open\"]),\n",
    "                calc_mean(stock_info_per_day[\"close\"]),\n",
    "                calc_mean(stock_info_per_day[\"high\"]),\n",
    "                calc_mean(stock_info_per_day[\"low\"]),\n",
    "                calc_mean(stock_info_per_day[\"volume\"]),\n",
    "                calc_mean(stock_info_per_day[\"money\"]),\n",
    "                calc_max(stock_info_per_day[\"high\"]),\n",
    "                calc_max(stock_info_per_day[\"volume\"]),\n",
    "                calc_max(stock_info_per_day[\"money\"]),\n",
    "                calc_min(stock_info_per_day[\"low\"]),\n",
    "                calc_min(stock_info_per_day[\"volume\"]),\n",
    "                calc_min(stock_info_per_day[\"money\"]),\n",
    "                calc_std(stock_info_per_day[\"volume\"]),\n",
    "                calc_std(stock_info_per_day[\"money\"]),\n",
    "                calc_var(stock_info_per_day[\"volume\"]),\n",
    "                calc_var(stock_info_per_day[\"money\"]),\n",
    "                calc_max(calc_div(calc_diff(stock_info_per_day[\"close\"], stock_info_per_day[\"open\"]), stock_info_per_day[\"open\"])),\n",
    "                calc_max(calc_div(calc_diff(stock_info_per_day[\"high\"], stock_info_per_day[\"low\"]), stock_info_per_day[\"open\"])),\n",
    "            ])\n",
    "            day_start = day_end\n",
    "        start = end\n",
    "    cols = [\n",
    "        \"open_mean\",\n",
    "        \"close_mean\",\n",
    "        \"high_mean\",\n",
    "        \"low_mean\",\n",
    "        \"volume_mean\",\n",
    "        \"money_mean\",\n",
    "        \"high_max\",\n",
    "        \"volume_max\",\n",
    "        \"money_max\",\n",
    "        \"low_min\",\n",
    "        \"volume_min\",\n",
    "        \"money_min\",\n",
    "        \"volume_std\",\n",
    "        \"money_std\",\n",
    "        \"volume_var\",\n",
    "        \"money_var\",\n",
    "        \"price_diff\",\n",
    "        \"price_diff_max\",\n",
    "    ]\n",
    "    mar_summary = pd.DataFrame(mar_summary, columns=cols)\n",
    "    combined = pd.concat([combined, mar_summary], axis=1)\n",
    "\n",
    "    return [combined, fun, mar, na_fun, na_mar, ret] if ret is not None else [combined, fun, mar, na_fun, na_mar]\n",
    "\n",
    "train = df.drop(columns=[\"date_time_x\", \"date_time_y\", \"day_s\", \"code\"]).fillna(0)\n",
    "test = test.rename(columns={\"date_time_x\": \"date_time\"}).drop(columns=[\"date_time_y\", \"day_s\", \"code\"]).fillna(0)\n",
    "\n",
    "train_fun, train_mar, train_ret = train, df_train_market, df_train_return\n",
    "test_fun, test_mar = test, df_test_market\n",
    "\n",
    "train_combined, train_fun, train_mar, train_na_fun, train_na_mar, train_ret = preprocess(train_fun, train_mar, train_ret)\n",
    "test_combined, test_fun, test_mar, test_na_fun, test_na_mar = preprocess(test_fun, test_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df):\n",
    "    df_cols = df.columns\n",
    "    if 'return' not in df_cols:\n",
    "        df_cols_prior = ['date_time', 'stock_id', 'day']\n",
    "    else:\n",
    "        df_cols_prior = ['date_time', 'stock_id', 'day', 'return']\n",
    "    for col in df_cols:\n",
    "        if col not in df_cols_prior:\n",
    "            df_cols_prior.append(col)\n",
    "    if 'return' in df_cols_prior:\n",
    "        df_cols_prior.remove('return')\n",
    "        df_cols_prior.append('return')\n",
    "    return df[df_cols_prior]\n",
    "\n",
    "train = reorder(train_combined)\n",
    "test = reorder(test_combined)\n",
    "\n",
    "train.to_csv(\"../../data/train_github.csv\", index=False)\n",
    "test.to_csv(\"../../data/test_github.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
